{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain.indexes import VectorstoreIndexCreator\n",
    "from langchain.indexes import VectorstoreIndexCreator\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "### your open_ai_api key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_API_KEY='Your Valid OpenAI API Key'\n",
    "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load_QA_Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The requirements for this program are as follows:\n",
      "\n",
      "1. The participant must have conducted similar trials in the past.\n",
      "2. The participant must have used cover crops in their field.\n",
      "3. The participant must be willing to share some of their personal information.\n",
      "4. The participant should not have been involved in exactly similar surveys with other companies in 2024.\n",
      "CPU times: total: 15.6 ms\n",
      "Wall time: 3.17 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "loader = TextLoader('chatbot_for_survey.txt', encoding='utf8')\n",
    "data = loader.load()\n",
    "llm = ChatOpenAI(temperature=0, openai_api_key=OPENAI_API_KEY)\n",
    "question = \"What are the requirements for this program?\"\n",
    "chain = load_qa_chain(llm, chain_type='stuff')\n",
    "result = chain.run(input_documents=data, question=question)\n",
    "# alternatively we can run this chain with the following command\n",
    "#answer=chain({\"input_documents\": data, \"question\": question},return_only_outputs=True)\n",
    "#print(answer['output_text'])\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## document chain: https://python.langchain.com/docs/modules/chains/document/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#[print(x) for x in dir(chain) if x[0] != '_']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VectorstoreIndexCreator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " To participate in this program, you must have conducted similar trials in the past, used cover crops in your field, be willing to share some of your personal information, and not have been involved in a similar survey with other companies in 2024.\n",
      "CPU times: total: 1.5 s\n",
      "Wall time: 3.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "loader = TextLoader('chatbot_for_survey.txt', encoding='utf8')\n",
    "index = VectorstoreIndexCreator().from_loaders([loader])\n",
    "answer=index.query(question)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "### providing parameters explicitly, we can change them if we want to use different parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 1260, which is longer than the specified 1000\n",
      "Number of requested results 4 is greater than number of elements in index 3, updating n_results = 3\n",
      "Number of requested results 4 is greater than number of elements in index 3, updating n_results = 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " To participate in this program, farmers must have conducted similar trials in the past, used cover crops in their field, be willing to share some of their personal information, and not have been involved in a similar survey with other companies in 2024.\n"
     ]
    }
   ],
   "source": [
    "index = VectorstoreIndexCreator(\n",
    "    # split the documents into chunks\n",
    "    text_splitter=CharacterTextSplitter(chunk_size=1000, chunk_overlap=0),\n",
    "    # select which embeddings we want to use\n",
    "    embedding=OpenAIEmbeddings(),\n",
    "    # use Chroma as the vectorestore to index and search embeddings\n",
    "    vectorstore_cls=Chroma\n",
    ").from_loaders([loader])\n",
    "index.query(llm=llm, question=question, chain_type=\"stuff\")\n",
    "print(index.query(question))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RetrivalQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The requirements for this program are:\n",
      "1. You must be willing to participate.\n",
      "2. You must have a farm from specific locations.\n",
      "3. You must fill up the form immediately upon enrolling in the program.\n",
      "CPU times: total: 172 ms\n",
      "Wall time: 3.82 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "loader = TextLoader('chatbot_for_survey.txt', encoding='utf8')\n",
    "data = loader.load()\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size = 100, chunk_overlap = 0, length_function = len)\n",
    "data = text_splitter.split_documents(data)\n",
    "llm = ChatOpenAI(temperature=0, openai_api_key=OPENAI_API_KEY)\n",
    "vectorstore = Chroma.from_documents(documents=data, embedding=OpenAIEmbeddings())\n",
    "# embedding_function = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "# retriever = Chroma.from_documents(docs, embedding_function)\n",
    "retriever = vectorstore.as_retriever(search_type='similarity', search_kwargs={'k': 3})\n",
    "qa_chain = RetrievalQA.from_chain_type(llm,retriever=retriever, chain_type='stuff')\n",
    "response=qa_chain({\"query\": question})\n",
    "result = response['result']\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text-embedding-ada-002\n",
      "text-embedding-davinci-001\n"
     ]
    }
   ],
   "source": [
    "embeddings = OpenAIEmbeddings()\n",
    "text = \"This is a test document.\"\n",
    "# this is default one\n",
    "print(embeddings.model)\n",
    "# change the default model, we can choose different embedding models\n",
    "embeddings = OpenAIEmbeddings(model='text-embedding-davinci-001')\n",
    "print(embeddings.model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(page_content='to participate in this program, you will have to fullfill the following commitments:', metadata={'source': 'chatbot_for_survey.txt'}), Document(page_content='are willing to participate in this program have to have farm from these locations. By participating', metadata={'source': 'chatbot_for_survey.txt'}), Document(page_content='marketing compain, you will be have fill up the form immeidatly you enrolled in this program.', metadata={'source': 'chatbot_for_survey.txt'}), Document(page_content='If your response is later than 09/30/2023, you will not be elegible to participate in this program.', metadata={'source': 'chatbot_for_survey.txt'}), Document(page_content='About this program: XYZ Survey Program for Lunching a New Corn Hybrid - X1276uyz-P', metadata={'source': 'chatbot_for_survey.txt'}), Document(page_content='3. they must be willing to share their some of their personal infomation', metadata={'source': 'chatbot_for_survey.txt'})]\n"
     ]
    }
   ],
   "source": [
    "## Checking the similarity search and finding relevent documents based on the provided question, here the default value of k  is 4. \n",
    "retriever = vectorstore.as_retriever(search_type='similarity', search_kwargs={'k': 6})\n",
    "relevant_docs = retriever.get_relevant_documents(question)\n",
    "print(relevant_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='to participate in this program, you will have to fullfill the following commitments:', metadata={'source': 'chatbot_for_survey.txt'}),\n",
       " Document(page_content='are willing to participate in this program have to have farm from these locations. By participating', metadata={'source': 'chatbot_for_survey.txt'}),\n",
       " Document(page_content='marketing compain, you will be have fill up the form immeidatly you enrolled in this program.', metadata={'source': 'chatbot_for_survey.txt'}),\n",
       " Document(page_content='If your response is later than 09/30/2023, you will not be elegible to participate in this program.', metadata={'source': 'chatbot_for_survey.txt'}),\n",
       " Document(page_content='About this program: XYZ Survey Program for Lunching a New Corn Hybrid - X1276uyz-P', metadata={'source': 'chatbot_for_survey.txt'}),\n",
       " Document(page_content='3. they must be willing to share their some of their personal infomation', metadata={'source': 'chatbot_for_survey.txt'})]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# also we can use one liner \n",
    "vectorstore.similarity_search(question, k=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#[print(x) for x in dir(qa_chain) if x[0] != '_']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Memory Based Conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = TextLoader('chatbot_for_survey.txt', encoding='utf8')\n",
    "data = loader.load()\n",
    "# text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "# documents = text_splitter.split_documents(data)\n",
    "# you encounter the following message: Created a chunk of size 1260, which is longer than the specified 1000\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=250, chunk_overlap=0, length_function = len,)\n",
    "documents = text_splitter.split_documents(data)\n",
    "embeddings = OpenAIEmbeddings()\n",
    "vectorstore = Chroma.from_documents(documents, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "#[x for x in dir(vectorstore) if x[0] != '_']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'question': 'What are the requirements for this program?', 'chat_history': [HumanMessage(content='What are the requirements for this program?', additional_kwargs={}, example=False), AIMessage(content='The requirements for this program are as follows:\\n1. The participant must have conducted similar trials in the past.\\n2. The participant must have used cover crops in their field.\\n3. The participant must have a farm located in specific locations.', additional_kwargs={}, example=False)], 'answer': 'The requirements for this program are as follows:\\n1. The participant must have conducted similar trials in the past.\\n2. The participant must have used cover crops in their field.\\n3. The participant must have a farm located in specific locations.'}\n",
      "The requirements for this program are as follows:\n",
      "1. The participant must have conducted similar trials in the past.\n",
      "2. The participant must have used cover crops in their field.\n",
      "3. The participant must have a farm located in specific locations.\n",
      "CPU times: total: 406 ms\n",
      "Wall time: 3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "loader = TextLoader('chatbot_for_survey.txt', encoding='utf8')\n",
    "data = loader.load()\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=250, chunk_overlap=0, length_function = len,)\n",
    "documents = text_splitter.split_documents(data)\n",
    "embeddings = OpenAIEmbeddings()\n",
    "vectorstore = Chroma.from_documents(documents, embeddings)\n",
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
    "#memory = ConversationBufferMemory(memory_key=\"chat_history\")\n",
    "qa = ConversationalRetrievalChain.from_llm(llm, vectorstore.as_retriever(), memory=memory)\n",
    "result=qa({\"question\":question})\n",
    "print(result)\n",
    "print(result['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='What are the requirements for this program?', additional_kwargs={}, example=False),\n",
       " AIMessage(content='The requirements for this program are as follows:\\n1. The participant must have conducted similar trials in the past.\\n2. The participant must have used cover crops in their field.\\n3. The participant must have a farm located in specific locations.', additional_kwargs={}, example=False)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['chat_history']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pass in chat history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Above we use memory object to track chat history. We can track the chat history without using memory object as follow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_with_memory(question, chat_history=[], k=3):\n",
    "    # initiating chain with out memory object here\n",
    "    qa = ConversationalRetrievalChain.from_llm(llm, vectorstore.as_retriever()) # make sure vectorstore and llm are defined aboved \n",
    "    result = qa({'question': question, 'chat_history': chat_history})\n",
    "    chat_history.append((question, result['answer']))\n",
    "    chat_history=chat_history[-k:]\n",
    "    return result, chat_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This program is about launching a new corn hybrid, specifically the X1276uyz-P. It is a survey program that involves marketing companies and all associated costs will be included. Participants in this program will need to fill out a form immediately upon enrollment. The program requires participants to fulfill certain commitments, such as having conducted similar trials in the past and using cover crops in their fields. Participants will receive compensation based on the area (acres) they use for the trial, with a maximum limit of 1000 acres.\n",
      "1\n",
      "\n",
      "\n",
      "The benefits for farmers participating in this program include receiving a premium offering for the first two years of using the product, as well as compensation based on the number of acres they use for the trial. The compensation rate is $10 per acre, with a maximum compensation of $10,000.\n",
      "2\n",
      "\n",
      "\n",
      "The payment will be made in two installments. The first installment of $50 will be provided upon agreement, and the remaining amount will be provided after the harvest is completed.\n",
      "3\n",
      "\n",
      "\n",
      "To join this program, you will need to follow these steps:\n",
      "\n",
      "1. Fill up the enrollment form immediately after you decide to participate.\n",
      "2. Make sure you have a farm located in one of the specified locations.\n",
      "3. Meet the commitments required for participation, which include:\n",
      "   a. Having conducted similar trials in the past.\n",
      "   b. Having used cover crops in your field.\n",
      "\n",
      "Once you have completed these steps, you will be eligible to join the XYZ Survey Program for Launching a New Corn Hybrid - X1276uyz-P.\n",
      "3\n",
      "\n",
      "\n",
      "Based on the given context, there is no specific mention of organic farming as a requirement or restriction for participation in the program. Therefore, it is unclear whether you can participate in the program if you practice organic farming.\n",
      "3\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "questions=[\"What is this program all about?\",\n",
    "\"How can farmers benefit from this?\",\n",
    "\"When will they will make the payment?\",\n",
    "\"What do I need to do to join in?\",\n",
    "\"Can I be part of this if I use organic farming?\"]\n",
    "\n",
    "chat_history = []\n",
    "for question in questions:\n",
    "    result, chat_history = ask_with_memory(question, chat_history)\n",
    "    print(result['answer'])\n",
    "    print(len(chat_history))\n",
    "    print('\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# qa = ConversationalRetrievalChain.from_llm(llm, vectorstore.as_retriever()) # initialize the chain without memory object\n",
    "# chat_history=[]\n",
    "# result = qa({'question': question, 'chat_history': chat_history})\n",
    "# chat_history.append((question, result['answer']))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Truncate the chat history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "question=\"where to contact?\"\n",
    "result = qa({'question': question, 'chat_history': chat_history})\n",
    "if len(chat_history) >= 3:\n",
    "    chat_history.append((question, result['answer']))\n",
    "    chat_history=chat_history[-3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chat_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('What do I need to do to join in?',\n",
       "  'To join this program, you will need to follow these steps:\\n\\n1. Fill up the enrollment form immediately after you decide to participate.\\n2. Make sure you have a farm located in one of the specified locations.\\n3. Meet the commitments required for participation, which include:\\n   a. Having conducted similar trials in the past.\\n   b. Having used cover crops in your field.\\n\\nOnce you have completed these steps, you will be eligible to join the XYZ Survey Program for Launching a New Corn Hybrid - X1276uyz-P.'),\n",
       " ('Can I be part of this if I use organic farming?',\n",
       "  'Based on the given context, there is no specific mention of organic farming as a requirement or restriction for participation in the program. Therefore, it is unclear whether you can participate in the program if you practice organic farming.'),\n",
       " ('where to contact?',\n",
       "  'You can reach out to us at help@xyz.com for any additional questions or inquiries. You can also visit our website at https://xyz.com for more information.')]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using ConversationBufferWindowMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'question': 'where to contact?', 'chat_history': [], 'answer': 'You can reach out to us at help@xyz.com for any additional questions or inquiries. Additionally, you can visit our website at https://xyz.com for more information about our program.'}\n"
     ]
    }
   ],
   "source": [
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "\n",
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n",
    "memory=ConversationBufferWindowMemory( k=3, memory_key=\"chat_history\", return_messages=True)\n",
    "#memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
    "#memory = ConversationBufferMemory(memory_key=\"chat_history\")\n",
    "\n",
    "qa = ConversationalRetrievalChain.from_llm(llm, vectorstore.as_retriever(), memory=memory)\n",
    "result=qa({\"question\":question})\n",
    "print(result)\n",
    "#print(result['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='where to contact?', additional_kwargs={}, example=False),\n",
       " AIMessage(content='You can reach out to us at help@xyz.com for any additional questions or inquiries. Additionally, you can visit our website at https://xyz.com for more information about our program.', additional_kwargs={}, example=False)]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result=qa({\"question\":'how the payment happens to this program?'})\n",
    "result['chat_history']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='where to contact?', additional_kwargs={}, example=False),\n",
       " AIMessage(content='You can reach out to us at help@xyz.com for any additional questions or inquiries. Additionally, you can visit our website at https://xyz.com for more information about our program.', additional_kwargs={}, example=False),\n",
       " HumanMessage(content='how the payment happens to this program?', additional_kwargs={}, example=False),\n",
       " AIMessage(content='The payment for this program will be provided in installments. The first installment of $50 will be provided upon agreement, and the remaining amount will be provided after the harvest is completed.', additional_kwargs={}, example=False)]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result=qa({\"question\":'who can participate in this program'})\n",
    "result['chat_history']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='where to contact?', additional_kwargs={}, example=False),\n",
       " AIMessage(content='You can reach out to us at help@xyz.com for any additional questions or inquiries. Additionally, you can visit our website at https://xyz.com for more information about our program.', additional_kwargs={}, example=False),\n",
       " HumanMessage(content='how the payment happens to this program?', additional_kwargs={}, example=False),\n",
       " AIMessage(content='The payment for this program will be provided in installments. The first installment of $50 will be provided upon agreement, and the remaining amount will be provided after the harvest is completed.', additional_kwargs={}, example=False),\n",
       " HumanMessage(content='who can participate in this program', additional_kwargs={}, example=False),\n",
       " AIMessage(content='To be eligible to participate in this program, individuals must have a farm located in specific locations. Additionally, they must have conducted similar trials in the past and have used cover crops in their fields.', additional_kwargs={}, example=False)]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result=qa({\"question\":'my farm is in IA, can I participate on this program?'})\n",
    "result['chat_history']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='how the payment happens to this program?', additional_kwargs={}, example=False),\n",
       " AIMessage(content='The payment for this program will be provided in installments. The first installment of $50 will be provided upon agreement, and the remaining amount will be provided after the harvest is completed.', additional_kwargs={}, example=False),\n",
       " HumanMessage(content='who can participate in this program', additional_kwargs={}, example=False),\n",
       " AIMessage(content='To be eligible to participate in this program, individuals must have a farm located in specific locations. Additionally, they must have conducted similar trials in the past and have used cover crops in their fields.', additional_kwargs={}, example=False),\n",
       " HumanMessage(content='my farm is in IA, can I participate on this program?', additional_kwargs={}, example=False),\n",
       " AIMessage(content='Yes, you can participate in this program if your farm is located in Iowa.', additional_kwargs={}, example=False)]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result=qa({\"question\":'where to start?'})\n",
    "result['chat_history']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "## we see above only three conversations are stored in memory and the old one is eliminated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Useful links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitter: https://python.langchain.com/docs/modules/data_connection/document_transformers/\n",
    "# article: https://dev.to/eteimz/understanding-langchains-recursivecharactertextsplitter-2846\n",
    "# chroma embedding: https://python.langchain.com/docs/integrations/vectorstores/chroma\n",
    "# open ai embedding: https://platform.openai.com/docs/guides/embeddings/what-are-embeddings\n",
    "# example embedding: https://python.langchain.com/docs/integrations/text_embedding/openai\n",
    "# Langchain tools: https://integrations.langchain.com/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
